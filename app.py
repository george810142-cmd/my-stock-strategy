import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
import os
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import warnings
from datetime import datetime, timedelta
import io
import requests
import gc # å¼•å…¥åƒåœ¾å›æ”¶æ©Ÿåˆ¶ï¼Œå¼·åˆ¶é‡‹æ”¾è¨˜æ†¶é«”

# å¿½ç•¥ pandas çš„ FutureWarning
warnings.simplefilter(action='ignore', category=FutureWarning)

# ==========================================
# âš™ï¸ è¨­å®šå€
# ==========================================
SHEET_NAME = 'AStock Overnight trading'

# âœ… åˆ†æ‰¹è™•ç†è¨­å®š (é—œéµå„ªåŒ–)
# æ¯æ¬¡åªè™•ç† 50 æª”è‚¡ç¥¨ï¼Œè™•ç†å®Œç«‹åˆ»é‡‹æ”¾è¨˜æ†¶é«”
BATCH_SIZE = 50 

# è¨­å®šå›æ¸¬æ™‚é–“
BACKTEST_PERIOD = "5y" 

CONFIG = {
    'MIN_PRICE': 2.0, 
    'MAX_PRICE': 1000.0, # é…åˆå¤§å‹è‚¡æ”¾å¯¬
    'MIN_VOLUME': 800000,
    'MARKET_FILTER_MA': 50, 
    'MARKET_FILTER': True,
    'MIN_RVOL': 2.5, 
    'MIN_RSI': 50,
    'MIN_MOMENTUM': 0.00, 
    'MAX_MOMENTUM': 0.25,
    'USE_MA60_FILTER': True, 
    'REQUIRE_GREEN_CANDLE': True,
    'STRONG_CLOSE_RATIO': 0.70, 
    'USE_VWAP_FILTER': True,
    'STOP_LOSS_PCT': -0.07,
    'HOLDING_COUNT': 3, 
    'HOLDING_DAYS': 5
}

# å‚™ç”¨æ¸…å–®
FALLBACK_TICKERS = ['AAPL', 'NVDA', 'MSFT', 'AMZN', 'GOOGL', 'META', 'TSLA']

# ==========================================
# 1. å–å¾— S&P 500 æˆåˆ†è‚¡
# ==========================================
@st.cache_data(ttl=3600*24)
def get_sp500_tickers():
    try:
        url = "https://raw.githubusercontent.com/datasets/s-and-p-500-companies/master/data/constituents.csv"
        response = requests.get(url)
        if response.status_code == 200:
            df = pd.read_csv(io.StringIO(response.text))
            tickers = df['Symbol'].tolist()
            clean_tickers = [t.replace('.', '-') for t in tickers]
            return clean_tickers
        return FALLBACK_TICKERS
    except: return FALLBACK_TICKERS

# ==========================================
# 2. Google Sheet é€£ç·š
# ==========================================
def connect_to_gsheet():
    try:
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        if "gcp_service_account" not in st.secrets:
            st.error("âŒ æœªåµæ¸¬åˆ° Secretsã€‚")
            return None
        key_dict = dict(st.secrets["gcp_service_account"])
        creds = ServiceAccountCredentials.from_json_keyfile_dict(key_dict, scope)
        client = gspread.authorize(creds)
        sheet = client.open(SHEET_NAME)
        return sheet
    except Exception as e:
        st.error(f"Google Sheet é€£ç·šå¤±æ•—: {e}")
        return None

def upload_dataframe(sheet, tab_name, df):
    if sheet is None: return
    try:
        try: worksheet = sheet.worksheet(tab_name)
        except: worksheet = sheet.add_worksheet(title=tab_name, rows="5000", cols="20")
        worksheet.clear()
        df_clean = df.fillna('').astype(str)
        data = [df_clean.columns.values.tolist()] + df_clean.values.tolist()
        worksheet.update(range_name='A1', values=data)
        st.success(f"âœ… ä¸Šå‚³æˆåŠŸ: [{tab_name}] - å…± {len(df)} ç­†")
    except Exception as e: st.error(f"âŒ ä¸Šå‚³å¤±æ•—: {e}")

# ==========================================
# 3. ç­–ç•¥æ ¸å¿ƒé‚è¼¯ (å–®ä¸€æ‰¹æ¬¡é‹ç®—)
# ==========================================
def process_batch_strategy(data, spy, market_signal):
    """è™•ç†å–®ä¸€æ‰¹æ¬¡çš„è‚¡ç¥¨æ•¸æ“š"""
    batch_candidates = []
    tickers = data.columns.levels[0].tolist()

    for ticker in tickers:
        try:
            df = data[ticker].copy().dropna()
            if len(df) < 60: continue 
            if df.index.tz is not None: df.index = df.index.tz_localize(None)

            # --- æŠ€è¡“æŒ‡æ¨™ ---
            df['MA60'] = df['Close'].rolling(60).mean()
            df['VolMA20'] = df['Volume'].rolling(20).mean().replace(0, 1)
            df['RVol'] = df['Volume'] / df['VolMA20']
            df['Close_20d'] = df['Close'].shift(20)
            df['Momentum_20d'] = (df['Close'] - df['Close_20d']) / df['Close_20d']
            
            delta = df['Close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
            rs = gain / loss
            df['RSI'] = 100 - (100 / (1 + rs))

            df['Range'] = df['High'] - df['Low']
            df['Close_Loc'] = np.where(df['Range'] > 0, (df['Close'] - df['Low']) / df['Range'], 0.5)
            df['Typical_Price'] = (df['High'] + df['Low'] + df['Close']) / 3
            df['Weekday'] = df.index.dayofweek

            # --- ç¯©é¸æ¢ä»¶ ---
            condition = (
                (df['Weekday'] == 0) & 
                (df['Close'] >= CONFIG['MIN_PRICE']) & (df['Close'] <= CONFIG['MAX_PRICE']) & 
                (df['Volume'] > CONFIG['MIN_VOLUME']) &
                (df['Close'] > df['MA60']) & 
                (df['Momentum_20d'] >= CONFIG['MIN_MOMENTUM']) & (df['Momentum_20d'] <= CONFIG['MAX_MOMENTUM']) & 
                (df['RVol'] > CONFIG['MIN_RVOL']) &
                (df['RSI'] > CONFIG['MIN_RSI']) &
                (df['Close'] > df['Open']) & 
                (df['Close_Loc'] > CONFIG['STRONG_CLOSE_RATIO']) & 
                (df['Close'] > df['Typical_Price'])
            )
            
            dates = df.index[condition]
            
            for date in dates:
                if not market_signal.get(date, False): continue
                loc = df.index.get_loc(date)
                monday_open = df.iloc[loc]
                
                # äº¤æ˜“åƒæ•¸
                buy_date = monday_open.name
                buy_price = float(monday_open['Open'])
                stop_price = buy_price * (1 + CONFIG['STOP_LOSS_PCT'])
                sell_date, sell_price, status = None, 0.0, ""
                
                # A. æ­·å²å›æ¸¬
                if loc + 5 < len(df):
                    week_data = df.iloc[loc:loc+5]
                    hit_stop = week_data['Low'] <= stop_price
                    if hit_stop.any():
                        status, sell_price = "StopLoss", stop_price
                        sell_date = week_data[hit_stop].index[0]
                    else:
                        status, sell_price = "Closed", float(df.iloc[loc+5]['Open'])
                        sell_date = df.iloc[loc+5].name
                # B. æŒå€‰ä¸­
                else:
                    days_passed = df.iloc[loc:]
                    hit_stop = days_passed['Low'] <= stop_price
                    if hit_stop.any():
                        status, sell_price = "StopLoss", stop_price
                        sell_date = days_passed[hit_stop].index[0]
                    else:
                        status, sell_date = "HOLD", "HOLDING"
                        sell_price = float(df.iloc[-1]['Close']) 

                pnl = sell_price - buy_price
                ret_pct = pnl / buy_price

                batch_candidates.append({
                    'Ticker': ticker, 'Buy_Date': buy_date, 'Buy_Price': round(buy_price, 2),
                    'Sell_Date': sell_date, 'Sell_Price': round(sell_price, 2),
                    'Profit': round(pnl, 2), 'Return_Pct': round(ret_pct * 100, 2),
                    'Status': status, 'RVol': round(monday_open['RVol'], 2)
                })

        except Exception: continue
        
    return batch_candidates

# ==========================================
# 4. ä¸‹é€±é æ¸¬ (ä½¿ç”¨æœ€å¾Œä¸€æ‰¹è³‡æ–™æˆ–é‡æ–°ä¸‹è¼‰)
# ==========================================
def predict_next_week(tickers, spy):
    # ç‚ºäº†ç¯€çœæ™‚é–“ï¼Œé€™è£¡åªé‡å° SPY ç‹€æ…‹è‰¯å¥½çš„æƒ…æ³ä¸‹ï¼Œå¿«é€Ÿæƒææ‰€æœ‰è‚¡ç¥¨çš„"æœ€æ–°ç‹€æ…‹"
    # ä¸‹è¼‰ "3mo" (3å€‹æœˆ) çš„æ•¸æ“šå°±å¤ åˆ¤æ–·æœ€æ–°è¨Šè™Ÿäº†ï¼Œé€Ÿåº¦å¿«å¾ˆå¤š
    candidates = []
    
    spy_ma = spy['Close'].rolling(CONFIG['MARKET_FILTER_MA']).mean().iloc[-1]
    if spy['Close'].iloc[-1] < spy_ma:
        st.warning("ğŸ›‘ å¤§ç›¤ç´…ç‡ˆ (SPY < MA50)ï¼Œç­–ç•¥å»ºè­°ä¸‹é€±ç©ºæ‰‹ã€‚")
        return pd.DataFrame()

    # æ‰¹æ¬¡ä¸‹è¼‰æœ€æ–°æ•¸æ“š
    for i in range(0, len(tickers), BATCH_SIZE * 2): # åŠ å¤§æ‰¹æ¬¡å› ç‚ºåªéœ€ä¸‹è¼‰å°‘æ•¸æ“š
        chunk = tickers[i:i + BATCH_SIZE * 2]
        try:
            data = yf.download(chunk, period="3mo", group_by='ticker', auto_adjust=False, threads=True, progress=False)
            if data.empty: continue
            
            # æ¸…ç†
            if len(chunk) == 1 and isinstance(data.columns, pd.Index): # å–®æª”è™•ç†
                 pass # ä¿æŒåŸæ¨£
            else:
                 data = data.dropna(axis=1, how='all')

            current_tickers = data.columns.levels[0].tolist() if isinstance(data.columns, pd.MultiIndex) else chunk

            for ticker in current_tickers:
                try:
                    df = data[ticker].dropna() if isinstance(data.columns, pd.MultiIndex) else data.dropna()
                    if df.empty: continue
                    curr = df.iloc[-1]
                    
                    # ç°¡æ˜“é‚è¼¯åˆ¤æ–·
                    close, volume = curr['Close'], curr['Volume']
                    if not (CONFIG['MIN_PRICE'] <= close <= CONFIG['MAX_PRICE']): continue
                    if volume <= CONFIG['MIN_VOLUME']: continue
                    
                    # RVol & Momentum
                    vol_ma20 = df['Volume'].rolling(20).mean().iloc[-1]
                    rvol = volume / vol_ma20 if vol_ma20 > 0 else 0
                    if rvol <= CONFIG['MIN_RVOL']: continue
                    
                    mom = (close - df['Close'].shift(20).iloc[-1]) / df['Close'].shift(20).iloc[-1]
                    if not (CONFIG['MIN_MOMENTUM'] <= mom <= CONFIG['MAX_MOMENTUM']): continue
                    
                    candidates.append({
                        'Ticker': ticker, 'Close': close, 'RVol': round(rvol, 2),
                        'Momentum': round(mom*100, 2)
                    })
                except: continue
            
            del data
            gc.collect() # å¼·åˆ¶æ¸…ç†
            
        except: continue

    df_next = pd.DataFrame(candidates)
    if not df_next.empty:
        return df_next.sort_values(by='RVol', ascending=False).head(5)
    return pd.DataFrame()

# ==========================================
# ğŸš€ ä¸»é é¢
# ==========================================
st.title("ğŸ“ˆ V60 ç¾è‚¡ç­–ç•¥å„€è¡¨æ¿ (SP500 Pro)")
st.caption(f"Mode: Batch Processing (Memory Safe) | Period: {BACKTEST_PERIOD}")

if st.button("ğŸš€ é–‹å§‹åŸ·è¡Œå…¨å¸‚å ´æƒæ"):
    
    # 1. æº–å‚™ SPY (åªéœ€ä¸‹è¼‰ä¸€æ¬¡)
    with st.spinner("ğŸ“¥ ä¸‹è¼‰å¤§ç›¤æ•¸æ“šä¸­..."):
        spy = yf.download("SPY", period=BACKTEST_PERIOD, progress=False, auto_adjust=False)
        if isinstance(spy.columns, pd.MultiIndex): spy.columns = spy.columns.get_level_values(0)
        spy_ma = spy['Close'].rolling(CONFIG['MARKET_FILTER_MA']).mean()
        market_signal = (spy['Close'] > spy_ma).to_dict()
    
    # 2. æº–å‚™è‚¡ç¥¨æ¸…å–®
    tickers = get_sp500_tickers()
    st.info(f"ğŸ“‹ é–å®š S&P 500 å…± {len(tickers)} æª”è‚¡ç¥¨ï¼Œæº–å‚™é€²è¡Œã€Œåˆ†æ‰¹é‹ç®—ã€ã€‚")

    # 3. åˆ†æ‰¹åŸ·è¡Œå›æ¸¬
    all_results = []
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    total_batches = (len(tickers) // BATCH_SIZE) + 1
    
    for i in range(0, len(tickers), BATCH_SIZE):
        chunk = tickers[i:i + BATCH_SIZE]
        batch_num = (i // BATCH_SIZE) + 1
        
        status_text.text(f"ğŸ”„ æ­£åœ¨è™•ç†ç¬¬ {batch_num}/{total_batches} æ‰¹æ¬¡ ({len(chunk)} æª”)...")
        progress_bar.progress(i / len(tickers))
        
        try:
            # A. ä¸‹è¼‰é€™ 50 æª”çš„ 5 å¹´æ•¸æ“š
            batch_data = yf.download(chunk, period=BACKTEST_PERIOD, group_by='ticker', auto_adjust=False, threads=True, progress=False)
            if batch_data.empty: continue
            
            # B. é‹ç®—ç­–ç•¥
            batch_results = process_batch_strategy(batch_data, spy, market_signal)
            all_results.extend(batch_results)
            
            # C. âš ï¸ é—œéµï¼šåˆªé™¤è®Šæ•¸ä¸¦å¼·åˆ¶å›æ”¶è¨˜æ†¶é«”
            del batch_data
            del batch_results
            gc.collect()
            
        except Exception as e:
            st.error(f"æ‰¹æ¬¡ {batch_num} å¤±æ•—: {e}")
            continue

    progress_bar.progress(100)
    status_text.success("âœ… å…¨å¸‚å ´æƒæå®Œæˆï¼")

    # 4. å½™æ•´çµæœ
    if all_results:
        df_all = pd.DataFrame(all_results)
        # ç¯©é¸æ¯é€± Top 3
        df_history = df_all.sort_values(by=['Buy_Date', 'RVol'], ascending=[True, False]) \
                           .groupby('Buy_Date').head(CONFIG['HOLDING_COUNT']).reset_index(drop=True)
        df_history = df_history.sort_values(by='Buy_Date', ascending=False)
        
        st.subheader("ğŸ“œ 5å¹´æ­·å²å›æ¸¬ç´€éŒ„ (S&P 500)")
        st.dataframe(df_history)
        
        total_ret = df_history['Return_Pct'].sum()
        win_rate = (df_history['Profit'] > 0).mean() * 100
        st.metric("æ­·å²ç¸½ç²åˆ© %", f"{total_ret:.2f}%", delta=f"å‹ç‡ {win_rate:.0f}%")
        
        # ä¸Šå‚³
        if st.checkbox("ğŸ“¤ ä¸Šå‚³æ­·å²ç´€éŒ„åˆ° Google Sheet?"):
            sheet = connect_to_gsheet()
            if sheet: upload_dataframe(sheet, "V60_SP500_5Y", df_history)
    else:
        st.warning("âš ï¸ ç„¡ç¬¦åˆè¨Šè™Ÿã€‚")

    # 5. é æ¸¬ä¸‹é€±
    st.write("---")
    st.subheader("ğŸ”® ä¸‹é€±ä¸€æ½›åœ¨æ¨™çš„")
    with st.spinner("æ­£åœ¨æƒææœ€æ–°æ•¸æ“š..."):
        df_next = predict_next_week(tickers, spy)
        if not df_next.empty:
            st.dataframe(df_next)
            if st.checkbox("ğŸ“¤ ä¸Šå‚³ä¸‹é€±æ¸…å–®åˆ° Google Sheet?"):
                sheet = connect_to_gsheet()
                if sheet: upload_dataframe(sheet, "V60_Next_Week", df_next)
        else:
            st.info("ç„¡ç¬¦åˆæ¨™çš„ã€‚")
